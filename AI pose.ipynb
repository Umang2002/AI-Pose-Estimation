{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1757667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe==0.9.1\n",
      "  Downloading mediapipe-0.9.1.0-cp39-cp39-win_amd64.whl (49.8 MB)\n",
      "     ---------------------------------------- 49.8/49.8 MB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from mediapipe==0.9.1) (3.6.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from mediapipe==0.9.1) (21.4.0)\n",
      "Requirement already satisfied: opencv-contrib-python in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from mediapipe==0.9.1) (4.7.0.72)\n",
      "Requirement already satisfied: numpy in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from mediapipe==0.9.1) (1.23.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from mediapipe==0.9.1) (20210226132247)\n",
      "Requirement already satisfied: absl-py in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from mediapipe==0.9.1) (0.15.0)\n",
      "Collecting protobuf<4,>=3.11\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
      "     -------------------------------------- 904.2/904.2 kB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from absl-py->mediapipe==0.9.1) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from matplotlib->mediapipe==0.9.1) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from matplotlib->mediapipe==0.9.1) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from matplotlib->mediapipe==0.9.1) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from matplotlib->mediapipe==0.9.1) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from matplotlib->mediapipe==0.9.1) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from matplotlib->mediapipe==0.9.1) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from matplotlib->mediapipe==0.9.1) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in u:\\anconda config\\envs\\env_1\\lib\\site-packages (from matplotlib->mediapipe==0.9.1) (9.4.0)\n",
      "Installing collected packages: protobuf, mediapipe\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.2\n",
      "    Uninstalling protobuf-4.23.2:\n",
      "      Successfully uninstalled protobuf-4.23.2\n",
      "  Attempting uninstall: mediapipe\n",
      "    Found existing installation: mediapipe 0.10.0\n",
      "    Uninstalling mediapipe-0.10.0:\n",
      "      Successfully uninstalled mediapipe-0.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'U:\\\\Anconda config\\\\envs\\\\env_1\\\\Lib\\\\site-packages\\\\~ediapipe\\\\python\\\\opencv_world3410.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe==0.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a68af4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in u:\\anconda config\\envs\\env_1\\lib\\site-packages (3.17.2)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.23.2-cp39-cp39-win_amd64.whl (422 kB)\n",
      "     -------------------------------------- 422.5/422.5 kB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.17.2\n",
      "    Uninstalling protobuf-3.17.2:\n",
      "      Successfully uninstalled protobuf-3.17.2\n",
      "Successfully installed protobuf-4.23.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.0 requires clang~=5.0, which is not installed.\n",
      "tensorflow 2.6.0 requires flatbuffers~=1.12, but you have flatbuffers 20210226132247 which is incompatible.\n",
      "tensorboard 2.6.0 requires google-auth<2,>=1.6.3, but you have google-auth 2.6.0 which is incompatible.\n",
      "streamlit 1.14.0 requires protobuf<4,>=3.12, but you have protobuf 4.23.2 which is incompatible.\n",
      "mediapipe 0.10.0 requires protobuf<4,>=3.11, but you have protobuf 4.23.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a990ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawings = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2427e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Feed\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow('Mediapipe Feed',frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break;\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd1a6a",
   "metadata": {},
   "source": [
    "### 1. Make detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "022810e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Feed\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.75,min_tracking_confidence =0.75) as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "    \n",
    "       ret,frame = cap.read()\n",
    "       \n",
    "       # Recolor image\n",
    "       image = cv2.cvtColor(frame ,cv2.COLOR_BGR2RGB)\n",
    "       image.flags.writeable= False\n",
    "       \n",
    "       # make detection\n",
    "       results = pose.process(image)\n",
    "       \n",
    "       # Recolor back to BGR \n",
    "       image.flags.writeable= True\n",
    "       image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "       #render detection\n",
    "       mp_drawings.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawings.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=2),\n",
    "                                 mp_drawings.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2)\n",
    "                                  \n",
    "                                 )\n",
    "    \n",
    " \n",
    "       cv2.imshow('Mediapipe Feed',image)\n",
    "    \n",
    "       if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break;\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ae99b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawings.draw_landmarks??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffbf3a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(0, 1),\n",
       "           (0, 4),\n",
       "           (1, 2),\n",
       "           (2, 3),\n",
       "           (3, 7),\n",
       "           (4, 5),\n",
       "           (5, 6),\n",
       "           (6, 8),\n",
       "           (9, 10),\n",
       "           (11, 12),\n",
       "           (11, 13),\n",
       "           (11, 23),\n",
       "           (12, 14),\n",
       "           (12, 24),\n",
       "           (13, 15),\n",
       "           (14, 16),\n",
       "           (15, 17),\n",
       "           (15, 19),\n",
       "           (15, 21),\n",
       "           (16, 18),\n",
       "           (16, 20),\n",
       "           (16, 22),\n",
       "           (17, 19),\n",
       "           (18, 20),\n",
       "           (23, 24),\n",
       "           (23, 25),\n",
       "           (24, 26),\n",
       "           (25, 27),\n",
       "           (26, 28),\n",
       "           (27, 29),\n",
       "           (27, 31),\n",
       "           (28, 30),\n",
       "           (28, 32),\n",
       "           (29, 31),\n",
       "           (30, 32)})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_pose.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa21973b",
   "metadata": {},
   "source": [
    "### Extract Joint Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a9f07410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Feed\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.75,min_tracking_confidence =0.75) as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "    \n",
    "       ret,frame = cap.read()\n",
    "       \n",
    "       # Recolor image\n",
    "       image = cv2.cvtColor(frame ,cv2.COLOR_BGR2RGB)\n",
    "       image.flags.writeable= False\n",
    "       \n",
    "       # make detection\n",
    "       results = pose.process(image)\n",
    "       \n",
    "       # Recolor back to BGR \n",
    "       image.flags.writeable= True\n",
    "       image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "      \n",
    "       # Extract Joints coordinates\n",
    "       try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "       except:\n",
    "             pass\n",
    "    \n",
    " \n",
    "       #render detection\n",
    "       mp_drawings.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawings.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=2),\n",
    "                                 mp_drawings.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2)\n",
    "                                  \n",
    "                                 )\n",
    "    \n",
    " \n",
    "       cv2.imshow('Mediapipe Feed',image)\n",
    "    \n",
    "       if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break;\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dce9158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "for lndmark in mp_pose.PoseLandmark:\n",
    "    print(lndmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6f80504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.5668584108352661\n",
       "y: 0.7541124224662781\n",
       "z: -2.2494168281555176\n",
       "visibility: 0.9896430969238281"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.NOSE.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48d1bf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(x: 0.8275439143180847\n",
       "y: 1.6389886140823364\n",
       "z: -1.9398555755615234\n",
       "visibility: 0.08690056204795837\n",
       ", dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0a0a9",
   "metadata": {},
   "source": [
    "### Calculate Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57116572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angles(a,b,c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1],c[0]-b[0])-np.arctan2(a[1]-b[1],a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77a98c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4406092166900635, 1.2866777181625366]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "shoulder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28443151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.568253219127655, 1.4779118299484253]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f698b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4783247411251068, 1.3939710855484009]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ddfd8e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.250258908316896\n"
     ]
    }
   ],
   "source": [
    "print(calculate_angles(shoulder,elbow,wrist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e0a69a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Feed\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.75,min_tracking_confidence =0.75) as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "    \n",
    "       ret,frame = cap.read()\n",
    "       \n",
    "       # Recolor image\n",
    "       image = cv2.cvtColor(frame ,cv2.COLOR_BGR2RGB)\n",
    "       image.flags.writeable= False\n",
    "       \n",
    "       # make detection\n",
    "       results = pose.process(image)\n",
    "       \n",
    "       # Recolor back to BGR \n",
    "       image.flags.writeable= True\n",
    "       image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "      \n",
    "       # Extract Joints coordinates\n",
    "       try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            #calculate the angle\n",
    "            angle = calculate_angles(shoulder,elbow,wrist)\n",
    "            \n",
    "            # visualize angle\n",
    "            cv2.putText(image,str(angle),\n",
    "                       tuple(np.multiply(elbow,[640,480]).astype(int)),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2,cv2.LINE_AA\n",
    "                        )\n",
    "       except:\n",
    "             pass\n",
    "       \n",
    "       \n",
    " \n",
    "       #render detection\n",
    "       mp_drawings.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawings.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=2),\n",
    "                                 mp_drawings.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2)\n",
    "                                  \n",
    "                                 )\n",
    "    \n",
    "       # Using resizeWindow()\n",
    "       cv2.namedWindow('Mediapipe Feed',cv2.WINDOW_NORMAL)\n",
    "       cv2.resizeWindow(\"Mediapipe Feed\", 640, 480)\n",
    "       cv2.imshow('Mediapipe Feed',image)\n",
    "       \n",
    "       if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break;\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa526065",
   "metadata": {},
   "source": [
    "### Curl Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2228a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Feed\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# curl counter variables\n",
    "counter =0\n",
    "stage = None\n",
    "with mp_pose.Pose(min_detection_confidence=0.75,min_tracking_confidence =0.75) as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "    \n",
    "       ret,frame = cap.read()\n",
    "       \n",
    "       # Recolor image\n",
    "       image = cv2.cvtColor(frame ,cv2.COLOR_BGR2RGB)\n",
    "       image.flags.writeable= False\n",
    "       \n",
    "       # make detection\n",
    "       results = pose.process(image)\n",
    "       \n",
    "       # Recolor back to BGR \n",
    "       image.flags.writeable= True\n",
    "       image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "      \n",
    "       # Extract Joints coordinates\n",
    "       try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            #calculate the angle\n",
    "            angle = calculate_angles(shoulder,elbow,wrist)\n",
    "            \n",
    "            # visualize angle\n",
    "            cv2.putText(image,str(angle),\n",
    "                       tuple(np.multiply(elbow,[640,480]).astype(int)),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2,cv2.LINE_AA\n",
    "                        )\n",
    "            \n",
    "            # curl counter logic\n",
    "            if angle > 160:\n",
    "                stage = \"down\"\n",
    "            if angle < 30 and stage == \"down\":\n",
    "                stage =\"up\"\n",
    "                counter+=1\n",
    "                \n",
    "       except:\n",
    "             pass\n",
    "       \n",
    "       # render counter\n",
    "       cv2.rectangle(image,(0,0),(225,73),(245,117,16),-1)\n",
    "       cv2.putText(image,\"REPS\",(15,12),\n",
    "                  cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "                  \n",
    "       cv2.putText(image,str(counter),\n",
    "                   (10,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Stage data\n",
    "       cv2.putText(image, 'STAGE', (65,12), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "       cv2.putText(image, stage, \n",
    "                    (60,60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "       #render detection\n",
    "       mp_drawings.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawings.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=2),\n",
    "                                 mp_drawings.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2)\n",
    "                                  \n",
    "                                 )\n",
    "    \n",
    "       # Using resizeWindow()\n",
    "       cv2.namedWindow('Mediapipe Feed',cv2.WINDOW_NORMAL)\n",
    "       cv2.resizeWindow(\"Mediapipe Feed\", 640, 480)\n",
    "       cv2.imshow('Mediapipe Feed',image)\n",
    "       \n",
    "       if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break;\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c914a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
